# Summary

| Date   | Notes
| :----- | :-------------------------------
| 07/24  | Met with everyone, assigned to work on img+cmd with Chau and Daisy, learned how to use jupyter notebook on server, familiarized myself with the training.py code. 
| 07/25  | Met with Chau and Daisy, debugged img+cmd code, applied the switching CPU code and got it working, also ran the training.py code successfully on my own computer. 
| 07/26  | Met with Chau and Daisy, set the CPU as an argument and also logged trained models as an artifact, met with everyone to share progress, tested out tracking loss and accuracy on wandb into training file but didn't work. 
| 07/27 | Met with Chau and Daisy to review pull request suggestions and make edits, meeting with everyone to try the img+cmd with inference, could not debug the dls error. 
| 07/28 | Met with Chau and Daisy to debug the splicing file name error, also met with Francisco to go over dls and export error again, started the fastai course to gain better idea of what we're doing. 

# Activities

- learned how to use the host server to set up jupyter notebook and use jupyter notebook to run experiments in wandb
- used the simple command: torch.cuda.set_device() to choose which CPU to use
    - afterwards, can also use the command: nvidia-smi to check CPU usage (command found in the wandb course) 
- practiced running the img+cmd file on my own wandb account and it worked

  <img width="1000" alt="Screenshot 2023 07 27" src="https://github.com/ellazhuu/ARCS-Reports/blob/master/Asset/Screen%20Shot%202023-07-27%20at%201.25.48%20AM.png">

- here is the artifact that was logged from the img+cmd script:

  <img width="1000" alt="Screenshot 2023 07 27 artifacts" src="https://github.com/ellazhuu/ARCS-Reports/blob/master/Asset/Screen%20Shot%202023-07-27%20at%201.26.14%20AM.png">

- explored how to track different metrics using wandb -> first tried it in my own project:
- here is the code: https://github.com/ellazhuu/ARCS-Reports/blob/master/Asset/wandb.ipynb 

- results in wandb:

<img width="1000" alt="Screenshot 2023 07 31" src="https://github.com/ellazhuu/ARCS-Reports/blob/master/Asset/Screen%20Shot%202023-07-31%20at%207.52.49%20PM.png">

- added img_size and valid_pct as argument inputs to the training script with Chau and Daisy
- also changed the splicing of the naming convention of the new data files  
  

# Issues
- ran into a problem when I couldn't log into wandb (kept on recieving the permission denied error message after pasting in the API), tried logging in before getting on the shared server, after getting on, before vs after launching jupyter notebook and same error 
- consulted Chau and Daisy about the error -> they told me to paste in a mkdir command and afterwards it worked

- while adapting the string splicing, we kept on getting the error where "10Trials" was being passed in and could not be converted into a float
  - solution: it was because the whole path was being passed into the function so we had to splice it from after 10Trials

- I tried to get the training.py runs to track charts (like loss or accuracy seen above) but I wasn't sure where to insert the line of code -> I tried going through the training.py code but I couldn't find where the loop of the experiment being run was so I wasn't sure where the best place would be to insert the code 

- when we tried to run the inference.py file with the training.py file, we kept on getting this error:
  - AttributeError: 'collections.OrderedDict' object has no attribute 'dls'
  - we hypotheize that it's because we did not export the model correctly in the training.py file.  

# Plans

- continue to investigate the dls issue
- continue testing out how to tract accuracy and loss with wandb
- start fastai course to gain better understanding of project  

